{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa92de0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:30:51.405799Z",
     "iopub.status.busy": "2025-07-12T20:30:51.405143Z",
     "iopub.status.idle": "2025-07-12T20:31:12.990559Z",
     "shell.execute_reply": "2025-07-12T20:31:12.989835Z"
    },
    "papermill": {
     "duration": 21.591789,
     "end_time": "2025-07-12T20:31:12.992046",
     "exception": false,
     "start_time": "2025-07-12T20:30:51.400257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047f61c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:12.999908Z",
     "iopub.status.busy": "2025-07-12T20:31:12.999497Z",
     "iopub.status.idle": "2025-07-12T20:31:13.014171Z",
     "shell.execute_reply": "2025-07-12T20:31:13.013398Z"
    },
    "papermill": {
     "duration": 0.019977,
     "end_time": "2025-07-12T20:31:13.015514",
     "exception": false,
     "start_time": "2025-07-12T20:31:12.995537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "fix_all_seeds(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236b7443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.022962Z",
     "iopub.status.busy": "2025-07-12T20:31:13.022753Z",
     "iopub.status.idle": "2025-07-12T20:31:13.116522Z",
     "shell.execute_reply": "2025-07-12T20:31:13.115827Z"
    },
    "papermill": {
     "duration": 0.098854,
     "end_time": "2025-07-12T20:31:13.117722",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.018868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"/kaggle/input/kaust-vs-kku-tournament-round-3/cells_segmentation/train.csv\"\n",
    "TRAIN_PATH = \"/kaggle/input/kaust-vs-kku-tournament-round-3/cells_segmentation/train\"\n",
    "TEST_PATH = \"/kaggle/input/kaust-vs-kku-tournament-round-3/cells_segmentation/test\"\n",
    "UNLABELED_PATH = \"/kaggle/input/kaust-vs-kku-tournament-round-3/cells_segmentation/unlabeled_additional_data\"\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "WIDTH = 704\n",
    "HEIGHT = 520\n",
    "PCT_IMAGES_VALIDATION = 0.1\n",
    "\n",
    "BATCH_SIZE = 2  # Reduced from 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 2  # Effective batch size = 2 * 2 = 4\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BOX_DETECTIONS_PER_IMG = 100  # Reduced from 150\n",
    "WARMUP_EPOCHS = 3\n",
    "\n",
    "# Enable mixed precision training\n",
    "USE_AMP = True\n",
    "\n",
    "BOXES_CONF = 0.1\n",
    "MASK_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1626f32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.125384Z",
     "iopub.status.busy": "2025-07-12T20:31:13.124862Z",
     "iopub.status.idle": "2025-07-12T20:31:13.132371Z",
     "shell.execute_reply": "2025-07-12T20:31:13.131873Z"
    },
    "papermill": {
     "duration": 0.012323,
     "end_time": "2025-07-12T20:31:13.133456",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.121133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transform(train=True, height=HEIGHT, width=WIDTH):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "            \n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "                A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "            ], p=0.7),\n",
    "            \n",
    "            A.OneOf([\n",
    "                A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.MedianBlur(blur_limit=5, p=1.0),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            A.OneOf([\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "                A.OpticalDistortion(distort_limit=0.5, shift_limit=0.5, p=1.0),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, \n",
    "                             border_mode=cv2.BORDER_CONSTANT, value=0, p=0.5),\n",
    "            \n",
    "            A.Resize(height, width, always_apply=True),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], always_apply=True),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(height, width, always_apply=True),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], always_apply=True),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9c1e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.140201Z",
     "iopub.status.busy": "2025-07-12T20:31:13.139944Z",
     "iopub.status.idle": "2025-07-12T20:31:13.146216Z",
     "shell.execute_reply": "2025-07-12T20:31:13.145434Z"
    },
    "papermill": {
     "duration": 0.010886,
     "end_time": "2025-07-12T20:31:13.147337",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.136451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape)\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): \n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return ' '.join(map(str, run_lengths))\n",
    "\n",
    "def remove_overlapping_pixels(mask, other_masks):\n",
    "    for other_mask in other_masks:\n",
    "        if np.sum(np.logical_and(mask, other_mask)) > 0:\n",
    "            mask[np.logical_and(mask, other_mask)] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d15389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.154197Z",
     "iopub.status.busy": "2025-07-12T20:31:13.153967Z",
     "iopub.status.idle": "2025-07-12T20:31:13.166177Z",
     "shell.execute_reply": "2025-07-12T20:31:13.165510Z"
    },
    "papermill": {
     "duration": 0.017067,
     "end_time": "2025-07-12T20:31:13.167300",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.150233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, image_dir, df, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.height = HEIGHT\n",
    "        self.width = WIDTH\n",
    "        \n",
    "        self.image_info = collections.defaultdict(dict)\n",
    "        temp_df = self.df.groupby('id')['annotation'].agg(lambda x: list(x)).reset_index()\n",
    "        for index, row in temp_df.iterrows():\n",
    "            self.image_info[index] = {\n",
    "                'image_id': row['id'],\n",
    "                'image_path': os.path.join(self.image_dir, row['id'] + '.png'),\n",
    "                'annotations': row[\"annotation\"]\n",
    "            }\n",
    "    \n",
    "    def get_box(self, a_mask):\n",
    "        pos = np.where(a_mask)\n",
    "        if len(pos[0]) == 0:\n",
    "            return [0, 0, 1, 1]\n",
    "        xmin = np.min(pos[1])\n",
    "        xmax = np.max(pos[1])\n",
    "        ymin = np.min(pos[0])\n",
    "        ymax = np.max(pos[0])\n",
    "        return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        info = self.image_info[idx]\n",
    "        img = Image.open(info['image_path']).convert(\"RGB\")\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        masks = []\n",
    "        boxes = []\n",
    "        for rle in info['annotations']:\n",
    "            mask = rle_decode(rle, (self.height, self.width)).astype('uint8')\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            masks.append(mask)\n",
    "            boxes.append(self.get_box(mask))\n",
    "\n",
    "        if len(masks) == 0:\n",
    "            masks = [np.zeros((self.height, self.width), dtype=np.uint8)]\n",
    "            boxes = [[0, 0, 1, 1]]\n",
    "\n",
    "        labels = [1] * len(masks)\n",
    "\n",
    "        if self.transforms:\n",
    "            try:\n",
    "                augmented = self.transforms(\n",
    "                    image=img_np,\n",
    "                    masks=masks,\n",
    "                    bboxes=boxes,\n",
    "                    labels=labels\n",
    "                )\n",
    "                img = augmented['image']\n",
    "                masks = [torch.as_tensor(m, dtype=torch.uint8) for m in augmented['masks']]\n",
    "                boxes = torch.as_tensor(augmented['bboxes'], dtype=torch.float32)\n",
    "                labels = torch.as_tensor(augmented['labels'], dtype=torch.int64)\n",
    "            except:\n",
    "                img = torchvision.transforms.ToTensor()(img_np)\n",
    "                masks = [torch.as_tensor(m, dtype=torch.uint8) for m in masks]\n",
    "                boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "                labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        else:\n",
    "            img = torchvision.transforms.ToTensor()(img_np)\n",
    "            masks = [torch.as_tensor(m, dtype=torch.uint8) for m in masks]\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        if len(masks) == 0:\n",
    "            masks = [torch.zeros((self.height, self.width), dtype=torch.uint8)]\n",
    "            boxes = torch.tensor([[0, 0, 1, 1]], dtype=torch.float32)\n",
    "            labels = torch.tensor([1], dtype=torch.int64)\n",
    "\n",
    "        masks = torch.stack(masks)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((labels.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'masks': masks,\n",
    "            'image_id': image_id,\n",
    "            'area': area,\n",
    "            'iscrowd': iscrowd\n",
    "        }\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0037a63c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.173809Z",
     "iopub.status.busy": "2025-07-12T20:31:13.173611Z",
     "iopub.status.idle": "2025-07-12T20:31:13.594574Z",
     "shell.execute_reply": "2025-07-12T20:31:13.593781Z"
    },
    "papermill": {
     "duration": 0.425607,
     "end_time": "2025-07-12T20:31:13.595781",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.170174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 381, Val images: 43\n",
      "Train annotations: 48918, Val annotations: 4147\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "df_base = pd.read_csv(TRAIN_CSV)\n",
    "unique_ids = df_base['id'].unique()\n",
    "train_ids, val_ids = train_test_split(\n",
    "    unique_ids,\n",
    "    test_size=PCT_IMAGES_VALIDATION,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "df_train = df_base[df_base['id'].isin(train_ids)]\n",
    "df_val = df_base[df_base['id'].isin(val_ids)]\n",
    "\n",
    "print(f\"Train images: {len(train_ids)}, Val images: {len(val_ids)}\")\n",
    "print(f\"Train annotations: {len(df_train)}, Val annotations: {len(df_val)}\")\n",
    "\n",
    "ds_train = CellDataset(TRAIN_PATH, df_train, transforms=get_transform(train=True))\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                      num_workers=2, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "ds_val = CellDataset(TRAIN_PATH, df_val, transforms=get_transform(train=False))\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                    num_workers=2, collate_fn=collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396b112c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:13.603174Z",
     "iopub.status.busy": "2025-07-12T20:31:13.602944Z",
     "iopub.status.idle": "2025-07-12T20:31:15.757378Z",
     "shell.execute_reply": "2025-07-12T20:31:15.756494Z"
    },
    "papermill": {
     "duration": 2.159653,
     "end_time": "2025-07-12T20:31:15.758705",
     "exception": false,
     "start_time": "2025-07-12T20:31:13.599052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|██████████| 170M/170M [00:00<00:00, 196MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Using single GPU with batch size 2 and gradient accumulation 2\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    NUM_CLASSES = 2\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "        pretrained=True,\n",
    "        box_detections_per_img=BOX_DETECTIONS_PER_IMG,\n",
    "        box_score_thresh=0.05,\n",
    "        box_nms_thresh=0.5,  # Increased for better filtering\n",
    "        rpn_score_thresh=0.05,\n",
    "        rpn_nms_thresh=0.7,\n",
    "        rpn_pre_nms_top_n_train=1000,  # Reduced from 2000\n",
    "        rpn_pre_nms_top_n_test=500,   # Reduced from 1000\n",
    "        rpn_post_nms_top_n_train=1000, # Reduced from 2000\n",
    "        rpn_post_nms_top_n_test=500    # Reduced from 1000\n",
    "    )\n",
    "    \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, NUM_CLASSES)\n",
    "    \n",
    "    # Enable gradient checkpointing to save memory\n",
    "    model.backbone.body.requires_grad_(True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Single GPU setup (no DataParallel)\n",
    "model = get_model()\n",
    "model = model.to(DEVICE)\n",
    "print(f\"→ Using single GPU with batch size {BATCH_SIZE} and gradient accumulation {GRADIENT_ACCUMULATION_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00dc6f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:15.767566Z",
     "iopub.status.busy": "2025-07-12T20:31:15.766977Z",
     "iopub.status.idle": "2025-07-12T20:31:15.774165Z",
     "shell.execute_reply": "2025-07-12T20:31:15.773648Z"
    },
    "papermill": {
     "duration": 0.01253,
     "end_time": "2025-07-12T20:31:15.775378",
     "exception": false,
     "start_time": "2025-07-12T20:31:15.762848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
    "\n",
    "def cosine_lr_scheduler(optimizer, total_epochs, warmup_epochs):\n",
    "    warmup_iters = warmup_epochs * len(dl_train)\n",
    "    warmup_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, 0.1)\n",
    "    main_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=total_epochs - warmup_epochs, eta_min=LEARNING_RATE * 0.01\n",
    "    )\n",
    "    return warmup_scheduler, main_scheduler\n",
    "\n",
    "warmup_scheduler, main_scheduler = cosine_lr_scheduler(optimizer, NUM_EPOCHS, WARMUP_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc88ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:15.784049Z",
     "iopub.status.busy": "2025-07-12T20:31:15.783850Z",
     "iopub.status.idle": "2025-07-12T20:31:15.796194Z",
     "shell.execute_reply": "2025-07-12T20:31:15.795696Z"
    },
    "papermill": {
     "duration": 0.018066,
     "end_time": "2025-07-12T20:31:15.797361",
     "exception": false,
     "start_time": "2025-07-12T20:31:15.779295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, warmup_scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    mask_loss_meter = AverageMeter()\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() if USE_AMP else None\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch}\")):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        if USE_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss for loss in loss_dict.values())\n",
    "                loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        else:\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        if USE_AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            if USE_AMP:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if warmup_scheduler is not None and epoch <= WARMUP_EPOCHS:\n",
    "                warmup_scheduler.step()\n",
    "        \n",
    "        loss_meter.update(loss.item() * GRADIENT_ACCUMULATION_STEPS, len(images))\n",
    "        if 'loss_mask' in loss_dict:\n",
    "            mask_loss_meter.update(loss_dict['loss_mask'].item(), len(images))\n",
    "        \n",
    "        # Clear cache every 10 batches\n",
    "        if batch_idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss_meter.avg, mask_loss_meter.avg\n",
    "            \n",
    "\n",
    "def validate_one_epoch(model, data_loader, device):\n",
    "    model.train()  # Keep in train mode to get losses\n",
    "    loss_meter = AverageMeter()\n",
    "    mask_loss_meter = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=\"Validation\")):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            if USE_AMP:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss_dict = model(images, targets)\n",
    "                    loss = sum(loss for loss in loss_dict.values())\n",
    "            else:\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            loss_meter.update(loss.item(), len(images))\n",
    "            if 'loss_mask' in loss_dict:\n",
    "                mask_loss_meter.update(loss_dict['loss_mask'].item(), len(images))\n",
    "            \n",
    "            # Clear cache every 5 batches during validation\n",
    "            if batch_idx % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss_meter.avg, mask_loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebbfbf2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:15.806257Z",
     "iopub.status.busy": "2025-07-12T20:31:15.805805Z",
     "iopub.status.idle": "2025-07-12T20:31:16.004043Z",
     "shell.execute_reply": "2025-07-12T20:31:16.003425Z"
    },
    "papermill": {
     "duration": 0.203328,
     "end_time": "2025-07-12T20:31:16.005170",
     "exception": false,
     "start_time": "2025-07-12T20:31:15.801842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory before training: 0.17 GB\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU cache before training\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU Memory before training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196eb998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T20:31:16.013491Z",
     "iopub.status.busy": "2025-07-12T20:31:16.013260Z",
     "iopub.status.idle": "2025-07-12T23:14:04.384654Z",
     "shell.execute_reply": "2025-07-12T23:14:04.383654Z"
    },
    "papermill": {
     "duration": 9768.377064,
     "end_time": "2025-07-12T23:14:04.385932",
     "exception": false,
     "start_time": "2025-07-12T20:31:16.008868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 191/191 [05:22<00:00,  1.69s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/30 - Train Loss: 2.3805 - Val Loss: 1.6677\n",
      "                 Train Mask: 0.7614 - Val Mask: 0.4154\n",
      "                 LR: 0.000125\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 191/191 [05:25<00:00,  1.70s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/30 - Train Loss: 1.9291 - Val Loss: 1.6101\n",
      "                 Train Mask: 0.5365 - Val Mask: 0.4116\n",
      "                 LR: 0.000199\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 191/191 [05:04<00:00,  1.60s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/30 - Train Loss: 1.8890 - Val Loss: 1.5868\n",
      "                 Train Mask: 0.5177 - Val Mask: 0.4117\n",
      "                 LR: 0.000274\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 191/191 [04:41<00:00,  1.47s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/30 - Train Loss: 1.8956 - Val Loss: 1.5829\n",
      "                 Train Mask: 0.5242 - Val Mask: 0.3924\n",
      "                 LR: 0.000273\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 191/191 [04:59<00:00,  1.57s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/30 - Train Loss: 1.8505 - Val Loss: 1.5296\n",
      "                 Train Mask: 0.5106 - Val Mask: 0.3898\n",
      "                 LR: 0.000270\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 191/191 [05:28<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/30 - Train Loss: 1.8140 - Val Loss: 1.5658\n",
      "                 Train Mask: 0.5120 - Val Mask: 0.3959\n",
      "                 LR: 0.000266\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 191/191 [05:26<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/30 - Train Loss: 1.8013 - Val Loss: 1.5328\n",
      "                 Train Mask: 0.5133 - Val Mask: 0.3912\n",
      "                 LR: 0.000260\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 191/191 [05:05<00:00,  1.60s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/30 - Train Loss: 1.7749 - Val Loss: 1.5627\n",
      "                 Train Mask: 0.5163 - Val Mask: 0.4348\n",
      "                 LR: 0.000252\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 191/191 [05:11<00:00,  1.63s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/30 - Train Loss: 1.7718 - Val Loss: 1.5381\n",
      "                 Train Mask: 0.5051 - Val Mask: 0.4019\n",
      "                 LR: 0.000242\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 191/191 [04:40<00:00,  1.47s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Train Loss: 1.7521 - Val Loss: 1.4662\n",
      "                 Train Mask: 0.5011 - Val Mask: 0.3970\n",
      "                 LR: 0.000232\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 191/191 [05:06<00:00,  1.60s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Train Loss: 1.7284 - Val Loss: 1.4840\n",
      "                 Train Mask: 0.4942 - Val Mask: 0.3997\n",
      "                 LR: 0.000220\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 191/191 [05:06<00:00,  1.60s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Train Loss: 1.7383 - Val Loss: 1.4673\n",
      "                 Train Mask: 0.4989 - Val Mask: 0.3955\n",
      "                 LR: 0.000207\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 191/191 [05:36<00:00,  1.76s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Train Loss: 1.7224 - Val Loss: 1.4826\n",
      "                 Train Mask: 0.4939 - Val Mask: 0.3794\n",
      "                 LR: 0.000193\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 191/191 [05:10<00:00,  1.63s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Train Loss: 1.7167 - Val Loss: 1.5578\n",
      "                 Train Mask: 0.4921 - Val Mask: 0.4165\n",
      "                 LR: 0.000178\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 191/191 [05:15<00:00,  1.65s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Train Loss: 1.6888 - Val Loss: 1.4610\n",
      "                 Train Mask: 0.4992 - Val Mask: 0.3881\n",
      "                 LR: 0.000163\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 191/191 [05:30<00:00,  1.73s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Train Loss: 1.6766 - Val Loss: 1.4798\n",
      "                 Train Mask: 0.4838 - Val Mask: 0.3828\n",
      "                 LR: 0.000147\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 191/191 [05:14<00:00,  1.65s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Train Loss: 1.6784 - Val Loss: 1.3993\n",
      "                 Train Mask: 0.4795 - Val Mask: 0.3521\n",
      "                 LR: 0.000132\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 191/191 [04:54<00:00,  1.54s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 - Train Loss: 1.6566 - Val Loss: 1.4244\n",
      "                 Train Mask: 0.4715 - Val Mask: 0.3481\n",
      "                 LR: 0.000116\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 191/191 [05:01<00:00,  1.58s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Train Loss: 1.6618 - Val Loss: 1.4524\n",
      "                 Train Mask: 0.4843 - Val Mask: 0.3808\n",
      "                 LR: 0.000101\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 191/191 [04:57<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Train Loss: 1.6299 - Val Loss: 1.4239\n",
      "                 Train Mask: 0.4772 - Val Mask: 0.3480\n",
      "                 LR: 0.000086\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 191/191 [05:42<00:00,  1.79s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Train Loss: 1.6253 - Val Loss: 1.4031\n",
      "                 Train Mask: 0.4690 - Val Mask: 0.3409\n",
      "                 LR: 0.000072\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 191/191 [05:20<00:00,  1.68s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Train Loss: 1.5950 - Val Loss: 1.4365\n",
      "                 Train Mask: 0.4714 - Val Mask: 0.3364\n",
      "                 LR: 0.000059\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 191/191 [05:35<00:00,  1.75s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Train Loss: 1.6141 - Val Loss: 1.4235\n",
      "                 Train Mask: 0.4752 - Val Mask: 0.3576\n",
      "                 LR: 0.000047\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 191/191 [05:10<00:00,  1.63s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Train Loss: 1.6000 - Val Loss: 1.3906\n",
      "                 Train Mask: 0.4676 - Val Mask: 0.3507\n",
      "                 LR: 0.000036\n",
      "                 New best model saved!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 191/191 [05:24<00:00,  1.70s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Train Loss: 1.5828 - Val Loss: 1.4358\n",
      "                 Train Mask: 0.4719 - Val Mask: 0.3494\n",
      "                 LR: 0.000027\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 191/191 [04:56<00:00,  1.55s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Train Loss: 1.5707 - Val Loss: 1.4109\n",
      "                 Train Mask: 0.4557 - Val Mask: 0.3519\n",
      "                 LR: 0.000019\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 191/191 [05:25<00:00,  1.70s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Train Loss: 1.5691 - Val Loss: 1.4077\n",
      "                 Train Mask: 0.4542 - Val Mask: 0.3537\n",
      "                 LR: 0.000013\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 191/191 [04:57<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - Train Loss: 1.5722 - Val Loss: 1.4147\n",
      "                 Train Mask: 0.4601 - Val Mask: 0.3629\n",
      "                 LR: 0.000009\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 191/191 [05:13<00:00,  1.64s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - Train Loss: 1.5777 - Val Loss: 1.4294\n",
      "                 Train Mask: 0.4634 - Val Mask: 0.3752\n",
      "                 LR: 0.000006\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 191/191 [05:15<00:00,  1.65s/it]\n",
      "Validation: 100%|██████████| 22/22 [00:11<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 - Train Loss: 1.5727 - Val Loss: 1.4342\n",
      "                 Train Mask: 0.4619 - Val Mask: 0.3769\n",
      "                 LR: 0.000005\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 8\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_mask_loss = train_one_epoch(\n",
    "        model, optimizer, dl_train, DEVICE, epoch, \n",
    "        warmup_scheduler if epoch <= WARMUP_EPOCHS else None\n",
    "    )\n",
    "    \n",
    "    val_loss, val_mask_loss = validate_one_epoch(model, dl_val, DEVICE)\n",
    "    \n",
    "    if epoch > WARMUP_EPOCHS:\n",
    "        main_scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{NUM_EPOCHS} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"                 Train Mask: {train_mask_loss:.4f} - Val Mask: {val_mask_loss:.4f}\")\n",
    "    print(f\"                 LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # In training loop, replace the save lines with:\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_to_save.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, 'best_model.pth')\n",
    "        print(f\"                 New best model saved!\")\n",
    "    \n",
    "    # And for regular checkpoints:\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_to_save.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, f'model_epoch_{epoch}.pth')\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bac9d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T23:14:04.996818Z",
     "iopub.status.busy": "2025-07-12T23:14:04.996000Z",
     "iopub.status.idle": "2025-07-12T23:14:05.021888Z",
     "shell.execute_reply": "2025-07-12T23:14:05.021335Z"
    },
    "papermill": {
     "duration": 0.297701,
     "end_time": "2025-07-12T23:14:05.023128",
     "exception": false,
     "start_time": "2025-07-12T23:14:04.725427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CellTestDataset(Dataset):\n",
    "    def __init__(self, image_dir, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.image_ids = [fname[:-4] for fname in os.listdir(self.image_dir) \n",
    "                          if fname.endswith('.png')]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_id + '.png')\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=img_np, bboxes=[], labels=[])\n",
    "            img_tensor = augmented['image']\n",
    "        else:\n",
    "            img_tensor = torchvision.transforms.ToTensor()(img)\n",
    "\n",
    "        return {'image': img_tensor, 'image_id': image_id}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "ds_test = CellTestDataset(TEST_PATH, transforms=get_transform(train=False))\n",
    "test_loader = DataLoader(ds_test, batch_size=1, shuffle=False, num_workers=2, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b7d0a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T23:14:05.553235Z",
     "iopub.status.busy": "2025-07-12T23:14:05.552908Z",
     "iopub.status.idle": "2025-07-12T23:14:07.097959Z",
     "shell.execute_reply": "2025-07-12T23:14:07.096910Z"
    },
    "papermill": {
     "duration": 1.812398,
     "end_time": "2025-07-12T23:14:07.099626",
     "exception": false,
     "start_time": "2025-07-12T23:14:05.287228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from epoch 24 with val_loss: 1.3906\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('best_model.pth')\n",
    "model = get_model()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# No DataParallel for inference (single batch)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']} with val_loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b06da31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T23:14:07.639214Z",
     "iopub.status.busy": "2025-07-12T23:14:07.638930Z",
     "iopub.status.idle": "2025-07-12T23:17:21.747109Z",
     "shell.execute_reply": "2025-07-12T23:17:21.745825Z"
    },
    "papermill": {
     "duration": 194.376788,
     "end_time": "2025-07-12T23:17:21.748500",
     "exception": false,
     "start_time": "2025-07-12T23:14:07.371712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 182/182 [03:13<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission created with 10391 entries\n",
      "Images with predictions: 10391\n",
      "Images without predictions: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_nms_to_masks(boxes, scores, masks, iou_threshold=0.3):\n",
    "    keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "    return boxes[keep], scores[keep], masks[keep]\n",
    "\n",
    "def post_process_masks(masks, min_area=50):\n",
    "    processed_masks = []\n",
    "    for mask in masks:\n",
    "        mask_np = mask.cpu().numpy()\n",
    "        if mask_np.sum() < min_area:\n",
    "            continue\n",
    "        processed_masks.append(mask_np)\n",
    "    return processed_masks\n",
    "\n",
    "submission = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Inference\"):\n",
    "        sample = batch[0]\n",
    "        img = sample['image'].to(DEVICE)\n",
    "        image_id = sample['image_id']\n",
    "        \n",
    "        outputs = model([img])[0]\n",
    "        \n",
    "        if len(outputs['masks']) == 0:\n",
    "            submission.append((image_id, \"-1\"))\n",
    "            continue\n",
    "        \n",
    "        boxes = outputs['boxes']\n",
    "        scores = outputs['scores']\n",
    "        masks = outputs['masks']\n",
    "        \n",
    "        mask_above_threshold = scores > BOXES_CONF\n",
    "        if not mask_above_threshold.any():\n",
    "            submission.append((image_id, \"-1\"))\n",
    "            continue\n",
    "            \n",
    "        boxes = boxes[mask_above_threshold]\n",
    "        scores = scores[mask_above_threshold]\n",
    "        masks = masks[mask_above_threshold]\n",
    "        \n",
    "        boxes, scores, masks = apply_nms_to_masks(boxes, scores, masks)\n",
    "        \n",
    "        any_mask = False\n",
    "        prev_masks = []\n",
    "        \n",
    "        for mask, score in zip(masks, scores):\n",
    "            mask_np = mask.cpu().numpy()\n",
    "            bin_mask = mask_np[0] > MASK_THRESHOLD\n",
    "            \n",
    "            if bin_mask.sum() < 20:\n",
    "                continue\n",
    "                \n",
    "            bin_mask = remove_overlapping_pixels(bin_mask, prev_masks)\n",
    "            \n",
    "            if bin_mask.sum() < 10:\n",
    "                continue\n",
    "                \n",
    "            prev_masks.append(bin_mask)\n",
    "            rle = rle_encoding(bin_mask.astype(np.uint8))\n",
    "            \n",
    "            if rle:\n",
    "                submission.append((image_id, rle))\n",
    "                any_mask = True\n",
    "        \n",
    "        if not any_mask:\n",
    "            submission.append((image_id, \"-1\"))\n",
    "\n",
    "df_sub = pd.DataFrame(submission, columns=['id', 'annotation'])\n",
    "df_sub[\"idx\"] = range(len(df_sub))\n",
    "df_sub = df_sub[[\"idx\", \"id\", \"annotation\"]].replace({\"\": \"-1\"})\n",
    "df_sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(f\"Submission created with {len(df_sub)} entries\")\n",
    "print(f\"Images with predictions: {len(df_sub[df_sub['annotation'] != '-1'])}\")\n",
    "print(f\"Images without predictions: {len(df_sub[df_sub['annotation'] == '-1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ace81",
   "metadata": {
    "papermill": {
     "duration": 0.284686,
     "end_time": "2025-07-12T23:17:22.312661",
     "exception": false,
     "start_time": "2025-07-12T23:17:22.027975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13015829,
     "sourceId": 107515,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10001.207176,
   "end_time": "2025-07-12T23:17:26.229115",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-12T20:30:45.021939",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
